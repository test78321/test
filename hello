import pandas as pd
import json
import ast
import argparse

parser = argparse.ArgumentParser(allow_abbrev=False, description="Json parser program !", epilog='Enjoy the parsing json! :)')
parser.add_argument('--jsonInputPath', action='store', type=str , default="sample.text", help="your json input file !")
parser.add_argument('--csvOutPutPath', action='store', type=str,  default="sample_out.csv", help="your parsed csv file !")
parser.add_argument('--metadataCsvFile', action='store', type=str, default="metadata.csv", help="your metadata csv file !")
parser.add_argument('--lookupCsvFile', action='store', type=str, default="lookup.csv", help="your lookup csv file !")


def read_json_as_dict(json_file):
    with open(json_file, 'r') as reader:
        return json.loads(ast.literal_eval(reader.read())['response'])


# without response
def read_json_as_dict_2(json_file):
    with open(json_file, 'r') as reader:
        return json.loads(reader.read())


def get_csv_df(csv_file):
    df=pd.read_csv(csv_file, index_col=0)
    df.columns = df.columns.str.replace(' ', '_')
    df.columns = df.columns.str.lower()
    return df


def get_decoded_or_lookup_value(df,encoded_column, value, decode_column):
    result=df.query('{} == "{}"'.format(encoded_column, value))
    if result.empty:
        return encoded_column
    else:
        return result.get(decode_column).values[0]


def isfloat(value):
  try:
    float(value)
    return True
  except ValueError:
    return False


def value_to_padded_double_standard(s,padding):
    # get decimal and integer padding
    padding_s=padding.split(".")
    if len(padding_s) == 1:
        padding_s.append("3")

    format_s = '{:0'+padding_s[0]+'.'+padding_s[1]+'f}'
    print(format_s)
    f = format_s.format(float(s))
    return f

def value_to_padded_double_including_digit(s, padding):
    # get decimal and integer padding
    padding_s = padding.split(".")
    if len(padding_s) == 1:
        padding_s.append("2")
    #s_s = s.split(".")
    sum = int(padding_s[0])+int(padding_s[1])+1
    format_s = '{:0'+str(sum)+'.'+padding_s[1]+'f}'
    f = format_s.format(float(s))
    return f


def value_to_padded_double_including_digit_exclude_sign(s, padding):
    # get decimal and integer padding
    padding_s = padding.split(".")
    if len(padding_s) == 1:
        padding_s.append("2")
    #s_s = s.split(".")
    sum = int(padding_s[0])+int(padding_s[1])+1
    if '-' in s:
        sum=sum+1
    format_s = '{:0'+str(sum)+'.'+padding_s[1]+'f}'
    f = format_s.format(float(s))
    return f


def value_to_padded_double(s, padding):
    # get decimal and integer padding
    padding_s = padding.split(".")
    if len(padding_s) == 1:
        padding_s.append("2")
    s_s = s.split(".")
    sum = int(padding_s[0])+len(s_s[0])+int(padding_s[1])+1
    format_s = '{:0'+str(sum)+'.'+padding_s[1]+'f}'
    f = format_s.format(float(s))
    return f


def value_to_padded_integer(value, padding):
    value_i = str(int(float(value))) if isfloat(value) else value
    return value_i.zfill(int(padding) + len(value_i))


def value_to_padded_integer_including_digit(value, padding):
    value_i = str(int(float(value))) if isfloat(value) else value
    return value_i.zfill(int(padding))


def value_to_padded_integer_including_digit_exclude_sign(value, padding):
    value_i = str(int(float(value))) if isfloat(value) else value
    if '-' in value_i:
        padding=padding+1
    return value_i.zfill(int(padding))


def parse_json_as_csv(json_dict: dict, csv_out:str, metadata_csv:str,lookup_csv:str):

    export_obj = []
    export_val = {}
    df_metadata = get_csv_df(metadata_csv)
    df_lookup = get_csv_df(lookup_csv)
    template_values = df_metadata['national_cards'].tolist()

    for x in json_dict["pipelineResults"]:
        for y in x['pipelineResult']:
            attributes = y["consumerData"]["attributes"]
            person_id = y["consumerData"]["person_id"]
            export_val["MEMBER_ID"] = get_decoded_or_lookup_value(df_lookup, "person_id", person_id, "member_id")
            # first write which is there in metadata then write rest
            for attr in attributes:
                value_f=''
                value:str = attr["value"]
                # get padding for value id
                padding = get_decoded_or_lookup_value(df_metadata,"national_cards",attr["id"], "padding")
                casting = get_decoded_or_lookup_value(df_metadata,"national_cards",attr["id"], "casting")
                if casting == 'Double':
                    value_f = value_to_padded_double_standard(value, str(padding))
                elif casting == 'Integer':
                    value_f = value_to_padded_integer_including_digit(value,padding)
                else:
                    value_f = value
                attr["value"] = value_f
                export_val[attr["id"]] = value_f
            export_obj.append(export_val)

    df_csv = pd.DataFrame.from_dict(rearrange_dict(export_obj,template_values))
    df_csv.to_csv(csv_out, index=False, header=True)


def parse_text_as_csv(csv_out:str, metadata_csv:str,lookup_csv:str):

    export_obj = []
    df_metadata = get_csv_df(metadata_csv)
    df_lookup = get_csv_df(lookup_csv)
    template_values = df_metadata['national_cards'].tolist()
    with open('sample.text') as reader:
        for line in reader:

            line_l = line.strip().split('"response":', 1)[1].strip()
            json_dict = json.loads(ast.literal_eval(line_l))

            for x in json_dict.get("pipelineResults") if json_dict.get("pipelineResults") else []:

                for y in x.get('pipelineResult') if x.get('pipelineResult') else [] :
                    attributes = y.get("consumerData").get("attributes") if y.get("consumerData") and y.get("consumerData").get("attributes") else []
                    if len(attributes) != 0:
                        export_val={}
                        person_id = y.get("consumerData").get("person_id")
                        export_val["MEMBER_ID"] = get_decoded_or_lookup_value(df_lookup, "person_id", person_id, "member_id")
                        # first write which is there in metadata then write rest
                        for attr in attributes:
                            value_f=''
                            value:str = attr["value"]
                            # get padding for value id
                            padding = get_decoded_or_lookup_value(df_metadata,"national_cards",attr["id"], "padding")
                            casting = get_decoded_or_lookup_value(df_metadata,"national_cards",attr["id"], "casting")
                            if casting == 'Double':
                                value_f = value_to_padded_double_standard(value, str(padding))
                            elif casting == 'Integer':
                                value_f = value_to_padded_integer_including_digit(value,padding)
                            else:
                                value_f = value
                            attr["value"] = value_f
                            export_val[attr["id"]] = value_f
                        export_obj.append(export_val)
                    else:
                        print("No Attribute there for consumer Id = {}".format(y.get("consumerData").get("person_id") if y.get("consumerData")else "No consumer data"))
        df_csv = pd.DataFrame.from_dict(rearrange_dict(export_obj,template_values))
        df_csv.to_csv(csv_out, index=False, header=True)

def rearrange_dict(dict_SL:list, m_list:list):
   dumped_object = []
   for dict_S in dict_SL:
     n_export_obj = {}
     for l in m_list:
        d_export_obj = {}
        for key in dict_S:
            if l == key or key == "MEMBER_ID":
                n_export_obj[key] = dict_S[key]
            else:
                d_export_obj[key]=dict_S[key]
     n_export_obj.update(d_export_obj)
     dumped_object.append(n_export_obj)
   return  dumped_object


if __name__ == '__main__':
    args = parser.parse_args()
    print("executing scripts with inputs as below...")
    print("input JSON => {}\nparsed CSV => {}\nmetadata CSV => {}\nlookup CSV => {}".format(args.jsonInputPath,
                                                                                            args.csvOutPutPath,
                                                                                            args.metadataCsvFile,
                                                                                            args.lookupCsvFile))

    parse_text_as_csv(args.csvOutPutPath,args.metadataCsvFile,args.lookupCsvFile)

# Else the module was imported and it has a __file__ attribute that will be the full path of the module.
else:
    print("not a script !")
